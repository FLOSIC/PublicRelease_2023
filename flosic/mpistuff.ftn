c
c **********************************************************************
c
      SUBROUTINE STOPIT
c
c abort the program in a clean way
c
        logical exist
%ifdef MPI
       INCLUDE 'mpif.h'
%endif
c        inquire(file='error',exist=exist)
c        if (.not.exist) then
           open (unit=11, file='ERROR_NRLMOL')
           write(11,*) 'Error  ...'
           close(11)
c        endif
%ifdef MPI
c
c       INCLUDE 'mpif.h'
       PRINT '(A)','Aborting MPI ...'
       

       CALL MPI_ABORT(MPI_COMM_WORLD,0,IERR)
c
%endif
c
       CALL FLUSH(6)
       STOP
      END
c
c **********************************************************************
c
      SUBROUTINE PVERSION()
c
c print statement if serial or parallel version is used
c
%ifdef MPI
c
       PRINT '(A)','MPI VERSION'
c
%else
c
       PRINT '(A)','SERIAL VERSION'
c
%endif
c
       RETURN
      END
c
c *******************************************************************
c
%ifdef MPI
c
c main routine for MPI
c
      PROGRAM MPICLUS
c 
c 09/11/97 David C. Patton
c 11/06/97 put in statistics (DCP)
c numerous fixes and extensions by DVP and MRP
c
c MPI Implementation of cluster code
c
c (note: specific MPI names are in caps)
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      INTEGER IERR,ERRCODE,LENGTH,JOB
      INTEGER I,NCALLED,TAG
      INTEGER IRECVSTAT(MPI_STATUS_SIZE)
      REAL*8  TIME1,TIME2
      CHARACTER*(MPI_MAX_PROCESSOR_NAME) NAME
      REAL*8 WCTIME(MX_PROC)
c
c setup MPI environment
c note: nproc is the number of processes-1 
c 
      CALL MPI_INIT(IERR) 
      IF (IERR.NE.0) THEN
       PRINT *,'Error starting MPI. Terminating'
       ERRCODE=0
       CALL MPI_ABORT(MPI_COMM_WORLD,ERRCODE,IERR)
      END IF
      CALL MPI_COMM_RANK(MPI_COMM_WORLD,IRANK,IERR)
      CALL MPI_COMM_SIZE(MPI_COMM_WORLD,NPROC,IERR)
      PRINT*,'MPI: Number of processes=',NPROC,' My rank=',IRANK
      IF (NPROC .GT. MX_PROC) THEN
       PRINT *,'mpiclus: mx_proc must be at least: ',NPROC
       CALL STOPIT
      END IF
      NPROC=NPROC-1
      CALL MPI_GET_PROCESSOR_NAME(NAME,LENGTH,IERR)
      PRINT *,'MPI: I am processor ',NAME(1:LENGTH)
c
      NCALLED=0
      DO I=1,NPROC
       INUSE(I)=0
      END DO
c
c startup cluster code on one node and cpuhog on the rest
c
      IF (IRANK.EQ.0) THEN
       TIME1=MPI_WTIME()
       CALL CLUSTER()
       JOB= -1
       TAG= 0
       DO I=1,NPROC
        CALL MPI_SSEND(JOB,1,MPI_INTEGER,I,TAG,MPI_COMM_WORLD,IERR)
       END DO
       TIME2= MPI_WTIME()
       PRINT *,' '
       PRINT *,'MPI: Total Wall clock TIME = ',TIME2-TIME1
       PRINT *,' '
c
c get some statistics and print them 
c
       DO I=1,NPROC
        TAG= 12
        CALL MPI_RECV(WCTIME(I),1,MPI_DOUBLE_PRECISION,I,
     &                TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       END DO 
       PRINT *,'***********************'
       PRINT *,'MPI Node       CPU time'
       PRINT *,'-----------------------'
       DO I=1,NPROC
        PRINT 1000,I,WCTIME(I)
1000    FORMAT(1X,I5,5X,F12.2)
       END DO
       PRINT *,'***************************************************'
      ELSE
       CALL CPUHOG
      END IF
c
c shutdown MPI
c
      print *, "Ending MPI"
      CALL MPI_FINALIZE(IERR)
      END
c
c *******************************************************************
c
      SUBROUTINE CKCHILD(MODE,TID)
c 
c 02/13/97 David Clay Patton
c 04/17/97 converted from PVM to MPI (DCP)
c 04/26/97 fixed call to mpi_iprobe so that mode 1 now works (DCP)
c 07/23/97 revised (DCP) 
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      INTEGER TID,NPROC,MODE,NCALLED,TAG,I
      INTEGER IRECVSTAT(MPI_STATUS_SIZE),IFLAG,IERR
c
      TID=0
      IF (NCALLED.EQ.0) RETURN
c
c check to see if any children are finished playing
c
      TAG=1
      IF (MODE.EQ.1) THEN
       CALL MPI_IPROBE(MPI_ANY_SOURCE,TAG,MPI_COMM_WORLD,
     &                 IFLAG,IRECVSTAT,IERR)
c     print*,'called mpi_iprobe:',iflag,tag,mpi_source,ncalled
c     print*,'irecvstat:',irecvstat(mpi_source)        
c     print*,'irecvstat:',irecvstat(mpi_any_source)        
c
c if so, get their tid
c
c fix for COMPAQ IFLAG=>ABS(IFLAG)
       IF (ABS(IFLAG).EQ.1) THEN
        CALL MPI_RECV(TID,1,MPI_INTEGER,IRECVSTAT(MPI_SOURCE),TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
        NCALLED=NCALLED-1
        CALL FREETID(TID)
       END IF
      END IF
c
c if all children are out playing then get result back from first to finish
c otherwise return immediately
c
      IF (MODE.EQ.2) THEN
       IF (NCALLED.EQ.NPROC) THEN
        CALL MPI_RECV(TID,1,MPI_INTEGER,MPI_ANY_SOURCE,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
        NCALLED=NCALLED-1
        CALL FREETID(TID)
       END IF
      END IF
c
c let all children finish
c
      IF (MODE.EQ.3) THEN 
       IF (NCALLED.NE.0) THEN
        DO I=1,NCALLED
         CALL MPI_RECV(TID,1,MPI_INTEGER,MPI_ANY_SOURCE,TAG,
     &                 MPI_COMM_WORLD,IRECVSTAT,IERR)
         CALL FREETID(TID)
        END DO
       END IF
       NCALLED=0
      END IF
c
c wait for the first child to finish
c
      IF (MODE.EQ.4) THEN 
       IF (NCALLED.EQ.0) RETURN
       CALL MPI_RECV(TID,1,MPI_INTEGER,MPI_ANY_SOURCE,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       NCALLED=NCALLED-1
       CALL FREETID(TID)
      END IF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE GETTID(TID) 
c
c get id for free node, stop if all nodes are busy
c 02/13/97 David Clay Patton
c changed 10/98 by DVP
c
      INCLUDE 'PARAMS'
      INCLUDE 'commons.inc'
      INTEGER NPROC,TID,I,NCALLED
      TID=0
      DO I=1,NPROC
       IF (INUSE(I).EQ.0) THEN
        TID=I
        GOTO 10
       END IF
      END DO
c
   10 IF (TID .EQ. 0) THEN
       PRINT *,'gettid: called while all nodes are busy'
       CALL STOPIT
      ELSE
       INUSE(TID)=1
      ENDIF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE GTNTID(TID) 
c
c get tid for free node or next available node     
c 12/02/99 Mark R. Pederson 
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      INTEGER NPROC,TID,I,NCALLED,IRECVSTAT(MPI_STATUS_SIZE)
      TID=0
      DO I=1,NPROC
       IF (INUSE(I).EQ.0) THEN
        TID=I
        INUSE(TID)=1
        GOTO 10
       END IF
      END DO
   10 IF (TID .EQ. 0) THEN
C WAIT FOR NEXT PROCESSOR TO FINISH
       TAG=1
       CALL MPI_IPROBE(MPI_ANY_SOURCE,TAG,MPI_COMM_WORLD,
     &                 IFLAG,IRECVSTAT,IERR)
        CALL MPI_RECV(TID,1,MPI_INTEGER,MPI_ANY_SOURCE,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
      ENDIF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE FREETID(TID)
c
c 02/13/97 David Clay Patton
c changed 10/98 by DVP
c
      INCLUDE 'PARAMS'
      INCLUDE 'commons.inc'
      INTEGER NPROC,TID,NCALLED
      IF ((TID .GE. 1) .AND. (TID.LE.NPROC)) THEN
       INUSE(TID)=0
      ELSE
       PRINT *,'freetid: called with invalid tid number: ',TID
       CALL STOPIT
      ENDIF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE CPUHOG 
c
c 07/23/97 David C. Patton, modified by DVP
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      INTEGER TAG,JOB,IERR,IRECVSTAT(MPI_STATUS_SIZE) 
c
      PRTIME=0.0D0
c
c check to see what type of task to perform
c
      JOB=0
      DO WHILE (JOB.GE.0)
       TAG=0
       CALL MPI_RECV(JOB,1,MPI_INTEGER,0,
     &               TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       PRTIME1=MPI_WTIME()
c
c global synchronization barrier
c
       IF (JOB.EQ.100) THEN
        CALL GLBARRIER
       END IF
c
c any kind of general data transfer
c
       IF (JOB.GT.100) THEN
        CALL SENDDATA(JOB)
       END IF
c
c get data and do cpu intensive work in poisson calculation
c     
       IF (JOB.EQ.3) CALL PASPOISS(1)
c 
c send in coulomb and rhog arrays 
c
       IF (JOB.EQ.4) CALL PASPOISS(2)
c
c receive data for gethold execution
c
       IF (JOB.EQ.5) CALL PASHAMIL(1)
c
c send gethold data to master
c
       IF (JOB.EQ.6) CALL PASHAMIL(2)
c
c deal with parallel calculation of XC and local potentials
c
       IF (JOB.EQ.7) CALL PASVLXC
c
c receive data for parallel forces and call frcslv
c
       IF (JOB.EQ.11) CALL PASFPUL(1)
c
c send force data created by frcslv
c
       IF (JOB.EQ.12) CALL PASFPUL(2) 
c
c receive input data for interstitial mesh and call fillist
c
       IF (JOB.EQ.14) CALL PASMESH(1)
c
c send mesh points to master
c
       IF (JOB.EQ.15) CALL PASMESH(2)
c
c recieive data  from master
       IF (JOB.EQ.16) CALL PASLS(1)
c
c send data  to  master
       IF (JOB.EQ.17) CALL PASLS(2)
c
c receive input data for diagge from NEWWAVE
c
       IF(JOB.EQ.20) CALL PASWAVE(1)
c
c send eigenvalues and vectors back
c
       IF(JOB.EQ.21) CALL PASWAVE(2)
C
c send data to slaves for rhofft  (fourier trans)
c
       IF(JOB.EQ.22) CALL PASFORM(1)
c
c get the results back
c
       IF(JOB.EQ.23) CALL PASFORM(2)

C
        IF(JOB.EQ.24) CALL  PASFLONASE 
C
        IF(JOB.EQ.25) CALL  PASNEWWAY  
C
       PRTIME2=MPI_WTIME()
       PRTIME=PRTIME+PRTIME2-PRTIME1
      END DO
c
c send total CPU time 
c
      TAG= 12
      CALL MPI_SSEND(PRTIME,1,MPI_DOUBLE_PRECISION,0,
     &               TAG,MPI_COMM_WORLD,IERR)   
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE GLBARRIER
c     
c this routine establishes a global synchronization barrier
c
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER IPROC,JOB,TAG,IERR
C
       JOB=100
       TAG=0
       IF (IRANK .EQ. 0) THEN
        DO IPROC= 1,NPROC
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
        END DO
       END IF
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
       RETURN
      END
c
c *******************************************************************
c
c this routine broadcasts data to the children
c depending on the value of job, different data sets will be sent
c valid ranges for job are from minjob to maxjob
c
      SUBROUTINE SENDDATA(JOB)
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       PARAMETER (MINJOB=101)
       PARAMETER (MAXJOB=107)
       INTEGER TAG,ROOT,SIZE,IERR,IPROC
       COMMON/TMP1/COULOMB(MAX_PTS),RHOG(MAX_PTS,NVGRAD,MXSPN)
       COMMON/TMP2/ RKPT(3,MXKPT),RHOKPT(2,2,MXKPT),NKPT     
       COMMON/MIXPOT/POTIN(MAX_PTS*MXSPN),POTOUT(MAX_PTS*MXSPN)
c
       COMMON/ISTITL/RNUC(3,MX_CNT),ZALP(2,MX_CNT),AFUDIS,ALONG
     &  ,IFNU(MX_CNT),NPOW(MX_CNT),NNUC,MX1D
c
       ROOT= 0
       TAG= 0 
       IF ((JOB .LT. MINJOB) .OR. (JOB .GT. MAXJOB)) THEN
        PRINT *,'invalid job number in senddata: ',JOB,IRANK
        CALL STOPIT 
       ENDIF
       IF (IRANK .EQ. 0) THEN
        DO IPROC= 1,NPROC
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
        END DO
       END IF
c
c send data from common blocks: debug, group, cblk11, base_rep,
c                               spin, dftyp, nuclei, baset, pspinf,
c                               bhspsp, tabpsp, pspnlo, rhopfit
c
       IF (JOB .EQ. 101) THEN
        CALL MPI_BCAST(DEBUG,1,MPI_LOGICAL,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NGRP,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RMAT,3*3*NGRP,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(MULTAB,MX_GRP*NGRP,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(N_REP,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NDMREP,N_REP,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(LDMREP,N_REP,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        SIZE= 5*5*MX_GRP*N_REP 
        CALL MPI_BCAST(REP,SIZE,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(S_REP,1*1*NGRP,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(P_REP,3*3*NGRP,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(D_REP,6*6*NGRP,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NSPN,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(IGGA,  2,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(IDFTYP,2,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NIDENT,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NCNT,  1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(IFUIDT,NIDENT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(IFUCNT,NCNT,  MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RIDT,3*NIDENT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RCNT,3*NCNT,  MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NFNCT,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(N_BARE,NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(N_CON,3*NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(LSYMMAX,NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(N_POS,NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(ZELC,NFNCT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(ZNUC,NFNCT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        SIZE= MAX_BARE*MAX_CON*LDIM*MAX_FUSET
C        PRINT*,'JUST BEFORE BFCON',SIZE
        CALL MPI_BCAST(BFCON,SIZE,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
C       PRINT*,'BFCON'
C       CALL STOPIT
        CALL MPI_BCAST(BFALP,MAX_BARE*NIDENT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(ISITPSP,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(ISNLCC, 1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        SIZE= NFNCT*7
        CALL MPI_BCAST(PSPSYM,SIZE,MPI_CHARACTER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NRADTAB,NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NLCC,NFNCT,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(LMAXNLO,NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NRPSP,NFNCT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(BHSALP,2*NFNCT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(BHSCOF,2*NFNCT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        call flush(6) 
        DO IFNCT= 1,NFNCT
         SIZE= NRADTAB(IFNCT)
         IF (SIZE .GT. 0) THEN
          CALL MPI_BCAST(RRADTAB(1,IFNCT),SIZE,MPI_DOUBLE_PRECISION,
     &                   ROOT,MPI_COMM_WORLD,IERR)
          CALL MPI_BCAST(VLRTAB(1,1,IFNCT),2*SIZE,MPI_DOUBLE_PRECISION,
     &                   ROOT,MPI_COMM_WORLD,IERR)
         END IF
         IF ((SIZE .GT. 0) .AND. (NLCC(IFNCT) .EQ. 1)) THEN
          CALL MPI_BCAST(RHOCOR(1,1,IFNCT),3*SIZE,MPI_DOUBLE_PRECISION,
     &                   ROOT,MPI_COMM_WORLD,IERR)
         END IF
         SIZE= NRPSP(IFNCT)
         IF (SIZE .GT. 0) THEN
          CALL MPI_BCAST(RPSNLO(1,IFNCT),SIZE,MPI_DOUBLE_PRECISION,
     &                   ROOT,MPI_COMM_WORLD,IERR)
          CALL MPI_BCAST(WPSNLO(1,IFNCT),SIZE,MPI_DOUBLE_PRECISION,
     &                   ROOT,MPI_COMM_WORLD,IERR)
          SIZE= SIZE*(MXLPSP+1)
          CALL MPI_BCAST(VPSNLO(1,1,IFNCT),SIZE,MPI_DOUBLE_PRECISION,
     &                   ROOT,MPI_COMM_WORLD,IERR)
         END IF
        END DO
        CALL MPI_BCAST(NRPFIT(1),NFNCT,MPI_INTEGER,
     &                 ROOT,MPI_COMM_WORLD,IERR)
        call flush(6) 
        CALL MPI_BCAST(LDIVR(1),NFNCT,MPI_INTEGER,
     &                 ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RPFALP(1),NFNCT,MPI_DOUBLE_PRECISION,
     &                 ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RPFCMX(1),NFNCT,MPI_DOUBLE_PRECISION,
     &                 ROOT,MPI_COMM_WORLD,IERR)
        DO IFNCT= 1,NFNCT
         SIZE= 2*NRPFIT(IFNCT)
         CALL MPI_BCAST(RPFCOF(1,1,IFNCT),SIZE,MPI_DOUBLE_PRECISION,
     &                  ROOT,MPI_COMM_WORLD,IERR)
        END DO
        RETURN
       END IF
c
c send mesh data
c
       IF (JOB .EQ. 102) THEN
        CALL MPI_BCAST(NMSH,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(WMSH,NMSH,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RMSH,3*NMSH,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        RETURN
       END IF
c
c send data for poisson (and initialize coulomb and rhog)
c
       IF (JOB .EQ. 103) THEN
        CALL MPI_BCAST(MODDEN,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        DO I=1,NMSH
         COULOMB(I)=0.0D0
        END DO
        IF (MODDEN .EQ. 1) THEN
         DO KSPN=1,NSPN
          DO J=1,10
           DO I=1,NMSH
            RHOG(I,J,KSPN)=0.0D0
           END DO
          END DO
         END DO
        END IF
        RETURN
       END IF
c
c send data for hamiltonian
c
       IF (JOB .EQ. 104) THEN
        CALL MPI_BCAST(N_SALC,MAXSYMSALC*3*NIDENT,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)       
        CALL MPI_BCAST(POTOUT,NMSH,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NSPHERES,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)       
        CALL MPI_BCAST(LIMSPH,2*NSPHERES,MPI_INTEGER,ROOT,
     &                 MPI_COMM_WORLD,IERR)       
        CALL MPI_BCAST(TSPH,4*NSPHERES,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)       
        RETURN
       END IF
c
c send general data for forces
c
       IF (JOB .EQ. 105) THEN
        CALL MPI_BCAST(NWF,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NWFS,NSPN,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(N_OCC,MAX_REP*NSPN,MPI_INTEGER,ROOT,
     &                  MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(INDBEG,MAX_IDENT*MAX_REP,MPI_INTEGER,ROOT,
     &                  MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(FRC1,3*NIDENT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(FRC2,3*NIDENT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(EVLOCC,MAX_OCC,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(POTOUT,NMSH*NSPN,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        SIZE= NDH*MAX_VIRT_PER_SYM*MAX_REP*NSPN
        CALL MPI_BCAST(PSI_COEF,SIZE,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        SIZE= MAX_VIRT_PER_SYM*MAX_REP*NSPN
        CALL MPI_BCAST(OCCUPANCY,SIZE,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        RETURN
       END IF
c
c send general data for creation of interstitial mesh
c initialize npts= 0 if not master node
c
       IF (JOB .EQ. 106) THEN
        CALL MPI_BCAST(NNUC,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(MX1D,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(NPOW,NNUC,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(IFNU,NNUC,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(ALONG,1,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(AFUDIS,1,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(ZALP,2*NNUC,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RNUC,3*NNUC,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)
        IF (IRANK .NE. 0) NMSH= 0
        RETURN
       END IF
c
c send data for formfak (and initialize rhokpt)
c
       IF (JOB .EQ. 107) THEN
        CALL MPI_BCAST(NKPT,1,MPI_INTEGER,ROOT,MPI_COMM_WORLD,IERR)
        CALL MPI_BCAST(RKPT,3*NIDENT,MPI_DOUBLE_PRECISION,ROOT,
     &                 MPI_COMM_WORLD,IERR)         
        DO IKPT=1,NKPT
         DO ISPN=1,NSPN
          RHOKPT(1,ISPN,IKPT)=0.0D0
          RHOKPT(2,ISPN,IKPT)=0.0D0
         END DO
        END DO
        RETURN
       END IF    
      END
c
c *******************************************************************
c
      SUBROUTINE PAMFPUL(MODE,MPTS,LPTS)
c
c calculate forces in parallel
c called by the master DVP 10/98
c
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER MODE,MPTS,LPTS
       COMMON/TMP2/FADD1(3,MAX_IDENT),FADD2(3,MAX_IDENT)
       INTEGER TID,JOB,TAG,IERR,ITRANS(2)
c
c produce fatal error if I'm a slave
c
       IF (IRANK.NE.0) THEN
        PRINT *,'FATAL: PAMFPUL CALLED BY SLAVE'
        CALL STOPIT
       END IF         
c
c mode= 1: send force data to slaves
c
       IF (MODE .EQ. 1) THEN
        NCALLED= NCALLED+1
        CALL GETTID(TID)
        JOB= 11
        TAG= 0
        CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
        ITRANS(1)= MPTS
        ITRANS(2)= LPTS
        TAG= 1101
        CALL MPI_SSEND(ITRANS(1),2,MPI_INTEGER,TID,
     &                 TAG,MPI_COMM_WORLD,IERR)
       END IF
c
c mode= 2: receive results from children
c
       IF (MODE.EQ.2) THEN
        CALL CKCHILD(3,NTID)
        DO IPROC=1,NPROC
         JOB= 12
         TAG= 0
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
        END DO
        CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
        CALL MPI_REDUCE(FRC1(1,1),FADD1(1,1),3*NIDENT,
     &                  MPI_DOUBLE_PRECISION,MPI_SUM,0,
     &                  MPI_COMM_WORLD,IERR) 
        CALL MPI_REDUCE(FRC2(1,1),FADD2(1,1),3*NIDENT,
     &                  MPI_DOUBLE_PRECISION,MPI_SUM,0,
     &                  MPI_COMM_WORLD,IERR) 
        DO IID= 1,NIDENT
         DO IX= 1,3
          FRC1(IX,IID)= FADD1(IX,IID)
          FRC2(IX,IID)= FADD2(IX,IID)
         END DO
        END DO
       END IF
      END
c
c *******************************************************************
c
      SUBROUTINE PASFPUL(MODE)
c
c calculate forces in parallel
c called by slaves DVP 10/98  
c
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER MODE
       INTEGER TAG,IERR,MPTS,LPTS,ITRANS(2),IRECVSTAT(MPI_STATUS_SIZE)
       COMMON/TMP3/BUF1(3,MAX_IDENT),BUF2(3,MAX_IDENT)
c
c produce fatal error if I'm the master
c
       IF (IRANK.EQ.0) THEN
        PRINT *,'FATAL: PASFPUL CALLED BY MASTER'
        CALL STOPIT
       END IF         
c
c mode= 1: receive data for parallel forces and call frcslv 
c
       IF (MODE .EQ. 1) THEN
        TAG= 1101
        CALL MPI_RECV(ITRANS(1),2,MPI_INTEGER,0,
     &                TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
        MPTS= ITRANS(1)
        LPTS= ITRANS(2)
        CALL FRCSLV(MPTS,LPTS)
        TAG=1
        CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR) 
       END IF
c
c mode= 2: send force data created by frcslv 
c
       IF (MODE.EQ.2) THEN
        CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
        CALL MPI_REDUCE(FRC1(1,1),BUF1(1,1),3*NIDENT,
     &                  MPI_DOUBLE_PRECISION,MPI_SUM,0,
     &                  MPI_COMM_WORLD,IERR) 
        CALL MPI_REDUCE(FRC2(1,1),BUF2(1,1),3*NIDENT,
     &                  MPI_DOUBLE_PRECISION,MPI_SUM,0,
     &                  MPI_COMM_WORLD,IERR) 
         DO IX=1,3
           DO IID=1,NIDENT
             FRC1(IX,IID)=BUF1(IX,IID)
             FRC2(IX,IID)=BUF2(IX,IID)
           END DO
         END DO
       END IF
      END
c
c *******************************************************************
c
      SUBROUTINE PAMHAMIL(MODE,IFNCT,JFNCT,AI,AJ,HSUB,MYIP)
c
c Subroutine for parallel hamiltonian called by master
c 20/03/98 Jens Kortus   kortus@theo.physik.tu-freiberg.de
c modifications by DV Porezag 08/99
c
c Mode 1: looking for a free node and sending all data
c Mode 2: receiving data and doing a call do gethold
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      INTEGER MODE,IFNCT,JFNCT,MYIP
      DIMENSION AI(3),AJ(3)
      DIMENSION HSUB(MAXUNSYM,MAXUNSYM)
      INTEGER TID,JOB,TAG,IERR,ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE)
c
c produce fatal error if I'm a slave
c
      IF (IRANK.NE.0) THEN
       PRINT *,'FATAL: PAMHAMIL CALLED BY SLAVE'
       CALL STOPIT
      END IF         
c
c send data for gethold execution
c
      IF (MODE.EQ.1) THEN
       NCALLED=NCALLED+1
       CALL GETTID(TID)
       JOB= 5
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       ITRANS(1)= IFNCT
       ITRANS(2)= JFNCT
       ITRANS(3)= MYIP 
       TAG= 501
       CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,
     &                TID,TAG,MPI_COMM_WORLD,IERR)   
       TAG= 502
       CALL MPI_SSEND(AI(1),3,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)   
       TAG= 503
       CALL MPI_SSEND(AJ(1),3,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)   
      END IF  
c
c receive gethold data from slave
C
      IF (MODE.EQ.2) THEN
       TAG=1
       CALL MPI_RECV(TID,1,MPI_INTEGER,MPI_ANY_SOURCE,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       JOB= 6
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       MXXX=MAXUNSYM*MAXUNSYM
       TAG= 601
       CALL MPI_RECV(HSUB(1,1),MXXX,MPI_DOUBLE_PRECISION,
     &               TID,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 602
       CALL MPI_RECV(MYIP,1,MPI_INTEGER,
     &               TID,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
 
       NCALLED=NCALLED-1
       CALL FREETID(TID)
      END IF  
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASHAMIL(MODE)
c
c J Kortus 1998
c code taken from cpuhog and moved into PASHAMIL by DV Porezag 08/1999
c
c Mode 1: receive data for call to gethold
c Mode 2: send data from call to gethold
c
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER MODE
       INTEGER TAG,IERR,IRECVSTAT(MPI_STATUS_SIZE)
       INTEGER IFNCT,JFNCT,MYIP,NEWIT,MXXX,ITRANS(3)
       DIMENSION AI(3),AJ(3),HSUB(MAXUNSYM,MAXUNSYM)
c
c produce fatal error if I'm the master
c
       IF (IRANK.EQ.0) THEN
        PRINT *,'FATAL: PASHAMIL CALLED BY MASTER'
        CALL STOPIT
       END IF         
c
c receive data for parallel hamiltonian
c
       IF (MODE.EQ.1) THEN
        TAG= 501
        CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
        IFNCT= ITRANS(1)
        JFNCT= ITRANS(2)
        MYIP=  ITRANS(3)
        TAG= 502
        CALL MPI_RECV(AI(1),3,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
        TAG= 503
        CALL MPI_RECV(AJ(1),3,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
c
c call gethold and tell mom I'm done
c
        NEWIT=1
        CALL GETHOLD(NEWIT,IFNCT,JFNCT,AI,AJ,HSUB)
        TAG=1
        CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,
     &                 MPI_COMM_WORLD,IERR)   
       ENDIF
c
c send gethold data to master
c
       IF (MODE.EQ.2) THEN
        MXXX=MAXUNSYM*MAXUNSYM
        TAG= 601
        CALL MPI_SSEND(HSUB(1,1),MXXX,MPI_DOUBLE_PRECISION,
     &                 0,TAG,MPI_COMM_WORLD,IERR)
        TAG= 602
        CALL MPI_SSEND(MYIP,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
       ENDIF
       RETURN
       END
c
c *******************************************************************
c
      SUBROUTINE PAMMESH(MODE,BOX,ERRBOX,NMULT)
c
c 12/98 Dirk V. Porezag 
c
c mode 1: send box data to slaves 
c mode 2: get mesh points from slaves
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      DIMENSION BOX(2,3)
      INTEGER MODE,NMULT
      INTEGER TID,JOB,TAG,IERR,MPTS,IRECVSTAT(MPI_STATUS_SIZE)
c
c produce fatal error if Im a slave
c
      IF (IRANK.NE.0) THEN
       PRINT *,'FATAL: PAMMESH CALLED BY SLAVE'
       CALL STOPIT
      END IF
c
c mode= 1: send data for interstitial mesh creation to slave
c
      IF (MODE.EQ.1) THEN
       NCALLED=NCALLED+1
       CALL GETTID(TID)
       JOB= 14
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1401
       CALL MPI_SSEND(BOX(1,1),6,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1402
       CALL MPI_SSEND(ERRBOX,1,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1403
       CALL MPI_SSEND(NMULT,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
      END IF
c
c mode= 2: receive mesh points from slaves
c
      IF (MODE.EQ.2) THEN
       CALL CKCHILD(3,NTID)
       DO 100 IPROC=1,NPROC
        JOB= 15
        TAG= 0
        CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
        TAG= 1501
        CALL MPI_RECV(MPTS,1,MPI_INTEGER,IPROC,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
        IF (MPTS .LE. 0) GOTO 100
        IF (NMSH+MPTS .GT. MAX_PTS) THEN
         PRINT *,'PAMMESH: MAX_PTS MUST BE AT LEAST: ',NMSH+MPTS
         CALL STOPIT
        END IF
        TAG= 1502
        CALL MPI_RECV(RMSH(1,NMSH+1),3*MPTS,MPI_DOUBLE_PRECISION,
     &                IPROC,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
        TAG= 1503
        CALL MPI_RECV(WMSH(NMSH+1),MPTS,MPI_DOUBLE_PRECISION,
     &                IPROC,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
        NMSH=NMSH+MPTS
  100  CONTINUE
      END IF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASMESH(MODE)
c
c 12/98 Dirk V. Porezag 
c
c mode 1: get box data from master and call fillist
c mode 2: send mesh points to master
c
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER MODE
       INTEGER TAG,IERR,IRECVSTAT(MPI_STATUS_SIZE)
       DIMENSION BOX(2,3)
       INTEGER NMULT
c
c produce fatal error if I'm the master
c
       IF (IRANK.EQ.0) THEN
        PRINT *,'FATAL: PASMESH CALLED BY MASTER'
        CALL STOPIT
       END IF    
      
c
c receive input data for interstitial mesh and call fillist 
c
       IF (MODE.EQ.1) THEN
        TAG= 1401
        CALL MPI_RECV(BOX(1,1),6,MPI_DOUBLE_PRECISION,0,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
        TAG= 1402
        CALL MPI_RECV(ERRBOX,1,MPI_DOUBLE_PRECISION,0,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
        TAG= 1403
        CALL MPI_RECV(NMULT,1,MPI_INTEGER,0,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
        CALL FILLIST(BOX,ERRBOX,NMULT)
        TAG=1
        CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
       END IF                      
c
c send mesh points to master
c  
       IF (MODE.EQ.2) THEN
        TAG= 1501
        CALL MPI_SSEND(NMSH,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
        IF (NMSH .GT. 0) THEN
         TAG= 1502
         CALL MPI_SSEND(RMSH(1,1),3*NMSH,MPI_DOUBLE_PRECISION,0,TAG,
     &                  MPI_COMM_WORLD,IERR)
         TAG= 1503
         CALL MPI_SSEND(WMSH(1),NMSH,MPI_DOUBLE_PRECISION,0,TAG,
     &                  MPI_COMM_WORLD,IERR)
        END IF
       END IF                            
       RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PAMLS(MODE,MPTS,P,V,CP,CHG,RKN,LMOM,DMOM) 
c
c subroutine for parallel L.S matrix evaluation called by master 
c 12/01/99 Mark R. Pederson   
c
c Mode 1: A free node is found via a call to gettid and the data from SPNORB  
c         is sent to the node for processing (a call of LSSLV (job2)
c Mode 2: The resultant data is collected from the nodes
c         and accumulated in the existing array H   (job 3)
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      PARAMETER (NMAX=MPBLOCK)
      PARAMETER (MDH=MAX_OCC)
      INTEGER   MODE,MPTS             
      INTEGER TID,JOB,TAG,IPROC,I,J
      INTEGER ICCL,ICCV
      LOGICAL OCCL,OCCV,LMOM,DMOM
      DIMENSION P(NMAX,3),V(NMAX),CP(NMAX,2)
      COMMON/UNRAVL/OCCL(MAX_OCC),OCCV(MAX_OCC)
      COMMON/TMP2/PSIG(4,NMAX,MAX_OCC),H(MAX_OCC,MAX_OCC,3)
      DIMENSION ADDBUF(MAX_OCC)
      DIMENSION ICCL(MAX_OCC),ICCV(MAX_OCC)
                    MOML=1
                    MOMD=1
                    IF(.NOT.LMOM)MOML=0
                    IF(.NOT.DMOM)MOMD=0
            DO I=1,NWF
            ICCL(I)=0
            ICCV(I)=0
            END DO
            DO I=1,NWF
            IF(OCCL(I))ICCL(I)=1 
            IF(OCCV(I))ICCV(I)=1
            END DO
c
c produce fatal error if I'm a slave
c
      IF (IRANK.NE.0) THEN
       PRINT *,'FATAL: PAMLS CALLED BY SLAVE'
       CALL STOPIT
      END IF 
c
c mode= 1: send data to children
c
      IF (MODE.EQ.1) THEN
      NCALLED=NCALLED+1
       CALL GTNTID(TID)
       JOB= 16
       TAG= 0
       CALL MPI_SSEND(JOB ,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1600
       CALL MPI_SSEND(NWF ,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1601
       CALL MPI_SSEND(MPTS,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1602
       CALL MPI_SSEND(P(1,1),3*NMAX,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1603 
       CALL MPI_SSEND(V(1),  NMAX,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1604
       CALL MPI_SSEND(CP(1,1),2*NMAX,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1605
       CALL MPI_SSEND(ICCL(1),MAX_OCC,MPI_INTEGER,          
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1606
       CALL MPI_SSEND(ICCV(1),MAX_OCC,MPI_INTEGER,          
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1607
       CALL MPI_SSEND(MOML,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 1608
       CALL MPI_SSEND(MOMD,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       IF(NCALLED.EQ.NPROC)THEN
C WAIT FOR A PROCESSOR TO FINISH...
       CALL CKCHILD(4,TID)
       END IF
      END IF
c
c master mode= 2: receive results from children
c
      IF (MODE.EQ.2) THEN
       CALL CKCHILD(3,TID)
       DO IPROC=1,NPROC
        JOB= 17
        TAG= 0
        CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
       END DO
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR) 
       CHG=0.0D0
       RKN=0.0D0
       CALL MPI_REDUCE(CHG,ADD,1,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
                       CHG=ADD
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR) 
       CALL MPI_REDUCE(RKN,ADD,1,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
                       RKN=ADD
CJK
       DO J=1,3
        DO I=1,NWF
         DO K=1,NWF
         H(K,I,J)=0.0D0
         ENDDO
        ENDDO
       ENDDO
CJK
       DO J=1,3
       DO I=1,NWF         
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR) 
       CALL MPI_REDUCE(H(1,I,J),ADDBUF(1),NWF,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
        DO K=1,NWF     
         H(K,I,J)=ADDBUF(K)
        END DO        
       END DO
       END DO
      END IF
      RETURN
      END
c *******************************************************************
c
      SUBROUTINE PASLS(MODE)
c
c subroutine for parallel L.S evaluation called by slave
c 12/01/99 Mark R. Pederson 
c
c Mode 1: The data is received from the master and LSSLV is called  (job 16)
c Mode 2: The resultant data are sent to the master (job 17)
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      PARAMETER (NMAX=MPBLOCK)
      PARAMETER (MDH=MAX_OCC)
      INTEGER MODE,MPTS             
      INTEGER TID,JOB,TAG,IPROC,I,J,IRECVSTAT(MPI_STATUS_SIZE)
      INTEGER ICCL,ICCV
      LOGICAL OCCL,OCCV,LMOM,DMOM
      DIMENSION P(NMAX,3),V(NMAX),CP(NMAX,2)
      COMMON/UNRAVL/OCCL(MAX_OCC),OCCV(MAX_OCC)
      COMMON/TMP2/PSIG(4,NMAX,MAX_OCC),H(MAX_OCC,MAX_OCC,3)
      DIMENSION ICCL(MAX_OCC),ICCV(MAX_OCC)
      COMMON/TMP3/TMPRECV(MAX_PTS)

c
c produce fatal error if I'm the master
c
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASLS CALLED BY MASTER'
       CALL STOPIT
      END IF
c
c slave mode= 1: receive data from master, call poisson
c
      TID= 0
      IF (MODE.EQ.1) THEN
       TAG= 1600
       CALL MPI_RECV(NWF,1,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1601
       CALL MPI_RECV(MPTS,1,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1602
       CALL MPI_RECV(P(1,1),3*NMAX,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1603 
       CALL MPI_RECV(V(1),  NMAX,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1604
       CALL MPI_RECV(CP(1,1),2*NMAX,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1605
       CALL MPI_RECV(ICCL(1),MAX_OCC,MPI_INTEGER,          
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1606
       CALL MPI_RECV(ICCV(1),MAX_OCC,MPI_INTEGER,          
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1607
       CALL MPI_RECV(MOML,1,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 1608
       CALL MPI_RECV(MOMD,1,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
                               LMOM=.FALSE.
                               DMOM=.FALSE.
                  IF(MOML.EQ.1)LMOM=.TRUE.
                  IF(MOMD.EQ.1)DMOM=.TRUE.
              DO I=NWF,1,-1
              OCCL(I)=.FALSE.
              OCCV(I)=.FALSE.
              END DO
              DO I=1,NWF
              IF(ICCL(I).EQ.1)OCCL(I)=.TRUE.
              IF(ICCV(I).EQ.1)OCCV(I)=.TRUE.
              END DO
c      CALL TSSLV(XX)!(MPTS,P,V,CP,CHG,RKE)
       CALL LSSLV(MPTS,P,V,CP,CHG,RKN,LMOM,DMOM)
c
c
c tell mom I'm done
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
      END IF                    
c
c slave mode= 2: send potential data to master via reduce
c
      IF (MODE.EQ.2) THEN
       TAG=1701
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
       CALL MPI_REDUCE(CHG ,ADD    ,1,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
               CHG=ADD
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
       CALL MPI_REDUCE(RKN ,ADD    ,1,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
               CHG=ADD
       DO I=1,3 
       DO J=1,NWF     
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
       CALL MPI_REDUCE(H(1,J,I),TMPRECV(1),NWF,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
        DO IB=1,NWF
           H(IB,J,I)=TMPRECV(IB)
        END DO
       END DO
       END DO
      END IF                 
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PAMPOISS(MODE,ND,MD,MINC,LNG,NWRD,POT,RHOG)
c
c subroutine for parallel poisson evaluation called by master 
c 09/16/97 David C. Patton
c updates and name change by D. Porezag
c
c Mode 1: A free node is found via a call to gettid and the data from COUPOT1 
c         is sent to the node for processing (a call of POISSON2) (job2)
c Mode 2: The resultant data (pot & rhog) is collected from the nodes
c         and accumulated in the existing array pot (job 3)
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      PARAMETER (MXPR=MXPOISS)
      PARAMETER (MXLG=3)
      LOGICAL   NWRD
      INTEGER   MODE,ND,MD,MINC,LNG
      DIMENSION POT(MAX_PTS),RHOG(MAX_PTS,NVGRAD,MXSPN)
      COMMON/COUPDATA/
     &  AIV(3,MXPR,MX_CNT+2,MXLG),AJV(3,MXPR,MX_CNT+2,MXLG)
     &  ,DMTV(10,10,MXPR,MX_CNT+2,MXLG),ALPIV(MXPR,MX_CNT+2,MXLG)
     &  ,ALPJV(MXPR,MX_CNT+2,MXLG),CENTER(3,MX_CNT+2)
     &  ,ADD(MAXUNSYM,MAXUNSYM,2),RVECI(3,MX_GRP),RVECJ(3,MX_GRP)
     &  ,NPAIRS(MX_CNT+2),IP(MX_CNT+2,MXLG)
      COMMON/TMP2/ADDBUF(MAX_PTS)
      INTEGER TID,JOB,TAG,NPAIR,IERR,NGRAD,IPROC,I,J,KSPN,ITRANS(3)
c
c produce fatal error if I'm a slave
c
      IF (IRANK.NE.0) THEN
       PRINT *,'FATAL: PAMPOISS CALLED BY SLAVE'
       CALL STOPIT
      END IF 
c
c mode= 1: send data to children
c
      IF (MODE.EQ.1) THEN
       NCALLED=NCALLED+1
       CALL GETTID(TID)
       JOB= 3
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 301
       CALL MPI_SSEND(NWRD,1,MPI_LOGICAL,TID,TAG,MPI_COMM_WORLD,IERR)
       NPAIR=IP(MINC,LNG)
       ITRANS(1)= NPAIR
       ITRANS(2)= ND
       ITRANS(3)= MD
       TAG= 302
       CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 303
       CALL MPI_SSEND(ALPIV(1,MINC,LNG),NPAIR,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 304
       CALL MPI_SSEND(AIV(1,1,MINC,LNG),3*NPAIR,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 305
       CALL MPI_SSEND(ALPJV(1,MINC,LNG),NPAIR,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 306
       CALL MPI_SSEND(AJV(1,1,MINC,LNG),3*NPAIR,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 307
       CALL MPI_SSEND(DMTV(1,1,1,MINC,LNG),10*10*NPAIR,
     &                MPI_DOUBLE_PRECISION,TID,TAG,MPI_COMM_WORLD,IERR)
      END IF
c
c master mode= 2: receive results from children
c
      IF (MODE.EQ.2) THEN
       CALL CKCHILD(3,TID)
       NGRAD=1
       IF ((IGGA(1).GT.0).OR.(IGGA(2).GT.0)) NGRAD=10
       DO IPROC=1,NPROC
        JOB= 4
        TAG= 0
        CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
       END DO
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR) 
       CALL MPI_REDUCE(POT(1),ADDBUF(1),NMSH,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
       DO I=1,NMSH
        POT(I)=ADDBUF(I)
       END DO        
       IF (MODDEN .EQ. 1) THEN
        DO KSPN=1,NSPN
         DO J=1,NGRAD
          CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
          CALL MPI_REDUCE(RHOG(1,J,KSPN),ADDBUF(1),NMSH,
     &                    MPI_DOUBLE_PRECISION,MPI_SUM,
     &                    0,MPI_COMM_WORLD,IERR)
          DO I=1,NMSH
           RHOG(I,J,KSPN)=ADDBUF(I)
          END DO
         END DO
        END DO
       END IF
      END IF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASPOISS(MODE)
c
c subroutine for parallel poisson evaluation called by slave
c 09/16/97 David C. Patton
c moved out of cpuhog into PSPOISS (D. Porezag, 08/1999)
c
c Mode 1: The data is received from the master and poisson is called  (job 2)
c Mode 2: The resultant data (pot & rhog) are sent to the master (job 3)
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      COMMON/TMP1/COULOMB(MAX_PTS),RHOG(MAX_PTS,NVGRAD,MXSPN)
      LOGICAL   NWRD
      INTEGER   MODE,TAG,NGRAD,NPAIR,ND,MD,IERR
      INTEGER   ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE)
      DIMENSION ALPHA(MXPOISS),BETA(MXPOISS)
      DIMENSION A(3*MXPOISS),B(3*MXPOISS)
      DIMENSION RHO(10*10*MXPOISS)       
      COMMON/TMP3/TMPRECV(MAX_PTS)
c
c produce fatal error if I'm the master
c
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASPOISS CALLED BY MASTER'
       CALL STOPIT
      END IF
c
c slave mode= 1: receive data from master, call poisson
c
      IF (MODE.EQ.1) THEN
       TAG= 301
       CALL MPI_RECV(NWRD,1,MPI_LOGICAL,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 302
       CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       NPAIR= ITRANS(1)
       ND=    ITRANS(2)
       MD=    ITRANS(3)
       TAG= 303
       CALL MPI_RECV(ALPHA(1),NPAIR,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 304
       CALL MPI_RECV(A(1),3*NPAIR,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 305
       CALL MPI_RECV(BETA(1),NPAIR,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)                 
       TAG= 306
       CALL MPI_RECV(B(1),3*NPAIR,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 307
       CALL MPI_RECV(RHO(1),10*10*NPAIR,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       CALL POISSON2(NWRD,NPAIR,ND,MD,ALPHA,A,BETA,B,RHO)
c
c tell mom I'm done
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
      END IF                    
c
c slave mode= 2: send potential data to master via reduce
c
      IF (MODE.EQ.2) THEN
       NGRAD=1
       IF ((IGGA(1).GT.0) .OR. (IGGA(2).GT.0)) NGRAD=10
       TAG=401
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
       CALL MPI_REDUCE(COULOMB(1),TMPRECV(1),NMSH,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
           DO IB=1,NMSH
            COULOMB(IB)=TMPRECV(IB)
           END DO
       IF (MODDEN .EQ. 1) THEN
        DO KSPN=1,NSPN
         DO J=1,NGRAD
          CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
          CALL MPI_REDUCE(RHOG(1,J,KSPN),TMPRECV(1),NMSH,
     &                    MPI_DOUBLE_PRECISION,MPI_SUM,0,
     &                    MPI_COMM_WORLD,IERR)
          DO IB=1,NMSH
           RHOG(IB,J,KSPN)=TMPRECV(IB)
          END DO
         END DO
        END DO
       END IF
      END IF                 
      RETURN
      END
c
c *******************************************************************
c
C      SUBROUTINE PAMVLXC(NGRAD,NDIM,RHOG,VXC,VLO)
      SUBROUTINE PAMVLXC(NGRAD,NDxx,RHOG,VXC,VLO)
c
c subroutine for parallel evaluation of local and xc potential
c called by master 
c DV Porezag, 08/99
c
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER   NGRAD,NDIM
       PARAMETER (NDIM=MAX_PTS)
       DIMENSION RHOG(NDIM,NVGRAD,MXSPN),VXC(NDIM*MXSPN),VLO(NDIM)
       COMMON/TMP2/RHOV(10*MXSPN*MPBLOCK),VXCS(MXSPN*MPBLOCK)
     &  ,VLOS(MPBLOCK),RHOC(10,MPBLOCK),XTMP(3,MPBLOCK),DTMP(3,MPBLOCK)
     &  ,RTMP(MPBLOCK),VLOC(NSPEED)
       DIMENSION EXCVEC(4)
       INTEGER TAG,TID,IERR,IRECVSTAT(MPI_STATUS_SIZE)
       INTEGER NMAST,NSMALL,LPTS,MPTS,MODE,LREF,MDIM,NSIZE
       INTEGER IFAC,ISPN,IGRAD,IOFS,IPTS,ITRANS(3)
c
c produce fatal error if Im a slave
c
       IF (IRANK.NE.0) THEN
        PRINT *,'FATAL: PAMVLXC CALLED BY SLAVE'
        CALL STOPIT
       END IF 
c
c determine maximum number of points for master, smallest allowed packet size
c     
       NMAST=  MPBLOCK/(3*NPROC+1)
       NSMALL= MPBLOCK/10 
C
C start looping over mesh points
C mode 1: all points sent out, wait for next slave to complete
C         and continue with mode 5
C      2: slaves are available for work
C      3: slaves are busy, do some work myself
C      4: slaves are busy, wait for next one to finish
C         and continue with mode 5
C      5: get data from slaves
C                        
       LPTS= 0
   10  CONTINUE
        MPTS= MIN(MPBLOCK,NMSH-LPTS)
        MODE= 0
        IF (MPTS .EQ. 0) THEN
         MODE= 1
         IF (NCALLED .EQ. 0) GOTO 20
         CALL CKCHILD(4,TID)
         MODE= 5
        ELSE
         IF (NCALLED.NE.NPROC) THEN
          MODE= 2
          NCALLED=NCALLED+1
          CALL GETTID(TID)
         ELSE
          MODE= 3
          MPTS= MIN(NMAST,MPTS)
          IF ((MPTS .LT. NSMALL) .AND. (MPTS .LT. NMSH-LPTS)) THEN
           MODE= 4
           CALL CKCHILD(4,TID)
           MODE= 5
          END IF
         END IF
        END IF
c
c mode 2,3: setup points
c
        IF ((MODE .EQ. 2) .OR. (MODE .EQ. 3)) THEN
         IFAC=NSPN*NGRAD
         DO ISPN=1,NSPN
          DO IGRAD=1,NGRAD
           IOFS= IGRAD+(ISPN-1)*NGRAD
           DO IPTS=1,MPTS
            RHOV(IOFS+IFAC*(IPTS-1))=RHOG(LPTS+IPTS,IGRAD,ISPN)
           END DO
          END DO
         END DO
        END IF
c
c mode 2: send job id and points, update lpts and return to beginning
c                                        
        IF (MODE .EQ. 2) THEN
         JOB= 7
         TAG= 0
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
         NSIZE= MPTS*NSPN*NGRAD
         ITRANS(1)= MPTS
         ITRANS(2)= LPTS
         ITRANS(3)= NSIZE
         TAG= 701
         CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG= 702
         CALL MPI_SSEND(RHOV(1),NSIZE,MPI_DOUBLE_PRECISION,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         LPTS= LPTS+MPTS
         GOTO 10
        END IF
c
c mode 3: call SUBVLXC
c
        LREF= LPTS
        MDIM= MPTS
        IF (MODE .EQ. 3) THEN
         CALL SUBVLXC(2,LPTS,MPTS,RHOV,VXCS,VLOS,EXCVEC)
         LPTS=LPTS+MPTS
        END IF
c
c mode 5: receive data from slave
c
        IF (MODE .EQ. 5) THEN
         TAG= 705
         CALL MPI_RECV(ITRANS(1),2,MPI_INTEGER,TID,TAG,
     &                 MPI_COMM_WORLD,IRECVSTAT,IERR)
         MDIM= ITRANS(1)
         LREF= ITRANS(2)
         TAG= 706
         CALL MPI_RECV(VXCS(1),MDIM*NSPN,MPI_DOUBLE_PRECISION,TID,
     &                 TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
         TAG= 707
         CALL MPI_RECV(VLOS(1),MDIM,MPI_DOUBLE_PRECISION,TID,
     &                 TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
         TAG= 708
         CALL MPI_RECV(EXCVEC(1),4,MPI_DOUBLE_PRECISION,TID,
     &                 TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
         IF ((LREF .LT. 0) .OR. (LREF+MDIM .GT. NMSH)) THEN
          PRINT *,'PAMVLXC: RETURNED INDICES ARE OUT OF BOUNDS'
          PRINT *,'LREF, MDIM, IRANK: ',LREF,MDIM,TID
          CALL STOPIT
         END IF
        END IF                               
c
c update arrays
c
        ERGXL=ERGXL+EXCVEC(1)
        ERGXN=ERGXN+EXCVEC(2)
        ERGCL=ERGCL+EXCVEC(3)
        ERGCN=ERGCN+EXCVEC(4)
        IOFS1=(NSPN-1)*NMSH
        IOFS2=(NSPN-1)*MDIM
        DO IPTS=1,MDIM
         VXC(LREF+IPTS)=VXCS(IPTS)
         VXC(LREF+IPTS+IOFS1)=VXCS(IPTS+IOFS2)
         VLO(LREF+IPTS)=VLOS(IPTS)
        END DO
        GOTO 10
   20  CONTINUE                      
       RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASVLXC
c
c 08/99 Dirk V. Porezag
c 
c Pasvlxc is called by a slave process to deal with the calculation
c of the exchange-correlation and coulomb potential
c 
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       COMMON/TMP2/RHOV(10*MXSPN*MPBLOCK),VXCS(MXSPN*MPBLOCK)
     &  ,VLOS(MPBLOCK),RHOC(10,MPBLOCK),XTMP(3,MPBLOCK),DTMP(3,MPBLOCK)
     &  ,RTMP(MPBLOCK),VLOC(NSPEED)
       INTEGER TAG,MPTS,LPTS,NSIZE,IERR
       INTEGER ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE)
       DIMENSION EXCVEC(4)
c
c produce fatal error if I'm the master
c
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASVLXC CALLED BY MASTER'
       CALL STOPIT
      END IF               
c
c get data and execute subvlxc
c
       TAG= 701
       CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       MPTS=  ITRANS(1)
       LPTS=  ITRANS(2)
       NSIZE= ITRANS(3)
       TAG= 702
       CALL MPI_RECV(RHOV(1),NSIZE,MPI_DOUBLE_PRECISION,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       CALL SUBVLXC(2,LPTS,MPTS,RHOV,VXCS,VLOS,EXCVEC)
c
c tell mom that I'm done and report results
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
       ITRANS(1)= MPTS
       ITRANS(2)= LPTS
       TAG= 705
       CALL MPI_SSEND(ITRANS(1),2,MPI_INTEGER,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 706
       CALL MPI_SSEND(VXCS(1),MPTS*NSPN,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 707
       CALL MPI_SSEND(VLOS(1),MPTS,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 708
       CALL MPI_SSEND(EXCVEC(1),4,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PAMWAVE(MODE,ISVD,IREP,NBAS)
C
C  SENDING BLOCKHAMILTONIANS TO SLAVES FOR DIAGGE
C  JK 09/99
C  MODE 1: LOOKING FOR A FREE NODE SENDING DATA
C  MODE 2: RECEIVING RESULTS OF DIAGGE
C
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'       
      INTEGER MODE,IREP
      INTEGER TID,JOB,TAG,IERR,ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE)         
c
c produce fatal error if I'm a slave
c
      IF (IRANK.NE.0) THEN
       PRINT *,'FATAL: PAMWAVE CALLED BY SLAVE'
       CALL STOPIT
      END IF
C
      IF (MODE.EQ.1) THEN
       NCALLED=NCALLED+1
       CALL GETTID(TID)
       JOB= 20
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,
     &     MPI_COMM_WORLD,IERR)
       TAG= 2000
       ITRANS(1)=IREP
       ITRANS(2)=ISVD
       ITRANS(3)=NBAS
       CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,TID,TAG,
     &                MPI_COMM_WORLD,IERR)
       TAG= 2001
       NDH2=NDH*NBAS
       CALL MPI_SSEND(HAM(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2002
       CALL MPI_SSEND(OVER(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
      END IF
c
c MODE = 2: RECEIVE RESULTS FROM DIAGGE
c
      IF (MODE.EQ.2) THEN
       TAG=1
       CALL MPI_RECV(TID,1,MPI_INTEGER,MPI_ANY_SOURCE,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       JOB= 21
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,
     &                MPI_COMM_WORLD,IERR)
       TAG=2100
       CALL MPI_RECV(ITRANS(1),2,MPI_INTEGER,
     &               TID,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       IREP=ITRANS(1)
       NBAS=ITRANS(2)
       NDH2=NDH*NBAS
       TAG= 2101
       CALL MPI_RECV(HAM(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &               TID,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2102
       CALL MPI_RECV(OVER(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &               TID,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2103
       CALL MPI_RECV(EVAL(1),NBAS,MPI_DOUBLE_PRECISION,
     &               TID,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
 
       NCALLED=NCALLED-1
       CALL FREETID(TID)
      END IF
      RETURN
      END           
c 
c *******************************************************************
c
      SUBROUTINE PASWAVE(MODE)
C
C  RECEIVING BLOCKHAMILTONIANS FOR DIAGGE
C  JK 09/99
C  MODE 1: RECEIVE DATA AND CALL DIAGGE
C  MODE 2: SEND RESULTS BACK
C
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'       
      INTEGER MODE
      INTEGER TID,JOB,TAG,IERR,ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE)         
      INTEGER IREP,ISVD,NBAS
c
C  ITRANS(1)=IREP
C  ITRANS(2)=ISVD
C  ITRANS(3)=NBAS
c
c produce fatal error if I'm master
c
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASWAVE CALLED BY MASTER'
       CALL STOPIT
      END IF
C
      IF (MODE.EQ.1) THEN
       TAG= 2000
       CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,0,TAG,
     &                MPI_COMM_WORLD,IRECVSTAT,IERR)
       IREP=ITRANS(1)
       ISVD=ITRANS(2)
       NBAS=ITRANS(3)
       TAG= 2001
       NDH2=NDH*NBAS
       CALL MPI_RECV(HAM(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2002
       CALL MPI_RECV(OVER(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
C
C call DIAGGE or SVD depending on ISVD, tell mom I'm done
        IF(ISVD.EQ.0) THEN
          CALL DIAGSVD(NDH,NBAS,NEIG,HAM,OVER,EVAL,
     &                  SC1,SC2,DSINGV,1)
          NBAS=NEIG 
        ELSE
          CALL DIAGGE(NDH,NBAS,HAM,OVER,EVAL,SC1,1)
        END IF                
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,
     &                 MPI_COMM_WORLD,IERR)                   
C
      END IF
c
c MODE = 2: SEND RESULTS BACK
c
      IF (MODE.EQ.2) THEN
       TAG=2100
       ITRANS(1)=IREP
       ITRANS(2)=NBAS
       CALL MPI_SSEND(ITRANS(1),2,MPI_INTEGER,
     &               0,TAG,MPI_COMM_WORLD,IERR)
       NDH2=NDH*NBAS
       TAG= 2101
       CALL MPI_SSEND(HAM(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2102
       CALL MPI_SSEND(OVER(1,1),NDH2,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2103
       CALL MPI_SSEND(EVAL(1),NBAS,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IERR)
 
      END IF
      RETURN
      END     
c 
c *******************************************************************
c
      SUBROUTINE PAMFORM(MODE,MUIV,MUJV,NCOUNT)
c
c subroutine for parallel fourier transorm of rho
c JK04/2000
c
c Mode 1: A free node is found via a call to gettid and the data 
c         is sent to the node for processing (a call of rhofftpar) (job2)
c Mode 2: The resultant data is collected from the nodes
c         and accumulated in the existing array rhokpt
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      PARAMETER (MXPR=MXPOISS)
      PARAMETER (MXLG=3)
      INTEGER   MODE
      DIMENSION MUIV(NCOUNT),MUJV(NCOUNT)
      COMMON/COUPDATA/
     &  AIV(3,MXPR*(MX_CNT+2)*MXLG),AJV(3,MXPR*(MX_CNT+2)*MXLG)
     &  ,DMTV(10,10,2,MXPR*(MX_CNT+2)*MXLG/2)
     &  ,ALPIV(MXPR*(MX_CNT+2)*MXLG)
     &  ,ALPJV(MXPR*(MX_CNT+2)*MXLG),CENTER(3,MX_CNT+2)
     &  ,ADD(MAXUNSYM,MAXUNSYM,2),RVECI(3,MX_GRP),RVECJ(3,MX_GRP)
     &  ,NPAIRS(MX_CNT+2),IP(MX_CNT+2,MXLG)       
      INTEGER TID,JOB,TAG,IERR,IPROC,I,J,ISPN
      COMMON/TMP2/ RKPT(3,MXKPT),RHOKPT(MXKPT,2,2),NKPT            
       COMMON/TMP3/BUF1(3*MAX_IDENT),BUF2(3*MAX_IDENT)
c
c produce fatal error if I'm a slave
c
      IF (IRANK.NE.0) THEN
       PRINT *,'FATAL: PAMFORM CALLED BY SLAVE'
       CALL STOPIT
      END IF 
c
c mode= 1: send data to children
c
      IF (MODE.EQ.1) THEN
       NCALLED=NCALLED+1
       CALL GETTID(TID)
       JOB= 22
       TAG= 0
       CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2201
       CALL MPI_SSEND(NCOUNT,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2203
       CALL MPI_SSEND(ALPIV(1),NCOUNT,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2204
       CALL MPI_SSEND(AIV(1,1),3*NCOUNT,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2205
       CALL MPI_SSEND(ALPJV(1),NCOUNT,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2206
       CALL MPI_SSEND(AJV(1,1),3*NCOUNT,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2207
       CALL MPI_SSEND(DMTV(1,1,1,1),10*10*2*NCOUNT,
     &                MPI_DOUBLE_PRECISION,TID,TAG,MPI_COMM_WORLD,IERR)
       TAG= 2208
       CALL MPI_SSEND(MUIV,NCOUNT,MPI_INTEGER,TID,TAG,
     &                MPI_COMM_WORLD,IERR)
       TAG= 2209
       CALL MPI_SSEND(MUJV,NCOUNT,MPI_INTEGER,TID,TAG,
     &                MPI_COMM_WORLD,IERR)
      END IF
c
c master mode= 2: receive results from children
c
      IF (MODE.EQ.2) THEN
       CALL CKCHILD(3,TID)
       DO IPROC=1,NPROC
        JOB= 23
        TAG= 0
        CALL MPI_SSEND(JOB,1,MPI_INTEGER,IPROC,TAG,MPI_COMM_WORLD,IERR)
       END DO
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR) 
       DO ISPN=1,NSPN
       CALL MPI_REDUCE(RHOKPT(1,1,ISPN),BUF1(1),
     &                 NKPT,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
       CALL MPI_REDUCE(RHOKPT(1,2,ISPN),BUF2(1),
     &                 NKPT,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
           DO IB=1,NKPT
              RHOKPT(IB,1,ISPN)=BUF1(IB)
              RHOKPT(IB,2,ISPN)=BUF2(IB)
           END DO
       ENDDO 
      END IF
      RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASFORM(MODE)
c
c subroutine for parallel evaluation of fourier transform of rho
c
c Mode 1: The data is received from the master and rhofftpar is called  (job 2)
c Mode 2: The resultant data are sent to the master (job 3)
c
      INCLUDE 'PARAMS'
      INCLUDE 'mpif.h'
      INCLUDE 'commons.inc'
      PARAMETER(MXFORM=MXPOISS)
      INTEGER   NCOUNT 
      INTEGER   MODE,TAG,IERR
      INTEGER   IRECVSTAT(MPI_STATUS_SIZE)
      DIMENSION ALPHA(MXFORM),BETA(MXFORM)
      DIMENSION A(3*MXFORM),B(3*MXFORM)
      DIMENSION RHO(10*10*2*MXFORM)
      DIMENSION MUIV(MXFORM),MUJV(MXFORM)       
      COMMON/TMP2/ RKPT(3,MXKPT),RHOKPT(MXKPT,2,2),NKPT
      COMMON/TMP3/BUF1(3*MAX_IDENT),BUF2(3*MAX_IDENT)
c
c produce fatal error if I'm the master
c
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASFORM CALLED BY MASTER'
       CALL STOPIT
      END IF
c
c slave mode= 1: receive data from master, call poisson
c
      IF (MODE.EQ.1) THEN
       TAG= 2201
       CALL MPI_RECV(NCOUNT,1,MPI_INTEGER,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2203
       CALL MPI_RECV(ALPHA(1),NCOUNT,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2204
       CALL MPI_RECV(A(1),3*NCOUNT,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2205
       CALL MPI_RECV(BETA(1),NCOUNT,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)                 
       TAG= 2206
       CALL MPI_RECV(B(1),3*NCOUNT,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2207
       CALL MPI_RECV(RHO(1),10*10*2*NCOUNT,MPI_DOUBLE_PRECISION,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2208
       CALL MPI_RECV(MUIV,NCOUNT,MPI_INTEGER,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 2209
       CALL MPI_RECV(MUJV,NCOUNT,MPI_INTEGER,
     &               0,TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)

       CALL RHOFFTPAR(ALPHA,BETA,A,B,DMTV,MUIV,MUJV,NCOUNT)
c
c tell mom I'm done
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
      END IF                    
c
c slave mode= 2: send rhokpt data to master via reduce
c
      IF (MODE.EQ.2) THEN
       TAG=2301
       CALL MPI_BARRIER(MPI_COMM_WORLD,IERR)
       DO ISPN=1,NSPN
       CALL MPI_REDUCE(RHOKPT(1,1,ISPN),BUF1(1),
     &     NKPT,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)
       CALL MPI_REDUCE(RHOKPT(1,2,ISPN),BUF2(1),
     &     NKPT,MPI_DOUBLE_PRECISION,
     &                 MPI_SUM,0,MPI_COMM_WORLD,IERR)

          DO IB=1,NKPT
              RHOKPT(IB,1,ISPN)=BUF1(IB)
              RHOKPT(IB,2,ISPN)=BUF2(IB)
          END DO
       ENDDO
      END IF                 
      RETURN
      END
c
c *******************************************************************
c
c


*******************************************************************
c       subroutine errorfile(Message)
c       character*50 Message
c       open (unit=11, file='error')
c        write(11,100) Message
c  100  format (A50)
c       close(11)
c       return
c       end
C
CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCc
C *******************************************************************
      SUBROUTINE PAMFLONASE(COULOMB)
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       PARAMETER (NMAX=MPBLOCK)
       PARAMETER (NDIM=MAX_PTS)
       DIMENSION COULOMB(MAX_PTS)
       COMMON/FORRx/NFLO,KSPX!!,TMAT(NDH,NDH,2)
       COMMON/TMP1/POT    (MAX_PTS),RHOG(MAX_PTS,NVGRAD,MXSPN)
       DIMENSION PSIG(NMAX,10,MAX_OCC),CV(NMAX),TV(NDH       )
     &  ,PTS(NSPEED,3),GRAD(NSPEED,10,6,MAX_CON,3)
     &  ,RVECA(3,MX_GRP),ICOUNT(MAX_CON,3)
       INTEGER TAG,TID,IERR,IRECVSTAT(MPI_STATUS_SIZE)
       INTEGER NMAST,NSMALL,LPTS,MPTS,MODE,LREF,MDIM,NSIZE
       INTEGER IFAC,ISPN,IGRAD,IOFS,IPTS,ITRANS(3),NFLO
       DOUBLE PRECISION TC
c
c produce fatal error if Im a slave
c
        print*,'NFLO in MPI_FLONASE',NFLO,NWFS,NWF
       IF (IRANK.NE.0) THEN
        PRINT *,'FATAL: PAMVLXC CALLED BY SLAVE'
        CALL STOPIT
       END IF 
       TV=0.0D0
       PT=0.0D0
c
c determine maximum number of points for master, smallest allowed packet size
c     
       NMAST=  MPBLOCK/(3*NPROC+1)
       NSMALL= MPBLOCK/10 
C
C start looping over mesh points
C mode 1: all points sent out, wait for next slave to complete
C         and continue with mode 5
C      2: slaves are available for work
C      3: slaves are busy, do some work myself
C      4: slaves are busy, wait for next one to finish
C         and continue with mode 5
C      5: get data from slaves
C                        
       LPTS= 0
   10  CONTINUE
        MPTS= MIN(MPBLOCK,NMSH-LPTS)
        MODE= 0
        IF (MPTS .EQ. 0) THEN
         MODE= 1
         IF (NCALLED .EQ. 0) GOTO 20
         CALL CKCHILD(4,TID)
         MODE= 5
        ELSE
         IF (NCALLED.NE.NPROC) THEN
          MODE= 2
          NCALLED=NCALLED+1
          CALL GETTID(TID)
         ELSE
          MODE= 3
          MPTS= MIN(NMAST,MPTS)
          IF ((MPTS .LT. NSMALL) .AND. (MPTS .LT. NMSH-LPTS)) THEN
           MODE= 4
           CALL CKCHILD(4,TID)
           MODE= 5
          END IF
         END IF
        END IF
c
c
      IF ((MODE .EQ. 2) .OR. (MODE .EQ. 3)) THEN
         DO I=1,NDH        
          TV(I)=TMAT(I,ABS(NFLO),KSPX)
         END DO
      END IF 
c mode 2: send job id and points, update lpts and return to beginning
c                                        
        IF (MODE .EQ. 2) THEN
         JOB= 24  
         TAG= 0
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
         NSIZE= MPTS
         ITRANS(1)= MPTS
         ITRANS(2)= LPTS
         ITRANS(3)= NFLO
         TAG= 8701
         CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG= 8702
         CALL MPI_SSEND(KSPX,1,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG=8703
         CALL MPI_SSEND(TV(1),NDH       ,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         LPTS= LPTS+MPTS
         GOTO 10
        END IF
c
c mode 3: call SUBVLXC
c
        LREF= LPTS
        MDIM= MPTS
        IF (MODE .EQ. 3) THEN
         CALL FLONASE(LPTS,MPTS,CV,TV)
         DO I=1,MPTS
         COULOMB(I+LPTS)=CV(I)
         END DO
C        CALL SUBVLXC(2,LPTS,MPTS,RHOV,VXCS,VLOS,EXCVEC)
         LPTS=LPTS+MPTS
        END IF
c
c mode 5: receive data from slave
c
        IF (MODE .EQ. 5) THEN
         TAG= 8705
         CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,TID,TAG,
     &                 MPI_COMM_WORLD,IRECVSTAT,IERR)
         MDIM= ITRANS(1)
         LREF= ITRANS(2)
       TAG= 8706
       CALL MPI_RECV(CV ,MDIM ,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
         DO I=1,MDIM
         COULOMB(I+LREF)=CV(I)
         END DO
         IF ((LREF .LT. 0) .OR. (LREF+MDIM .GT. NMSH)) THEN
          PRINT *,'PAMVLXC: RETURNED INDICES ARE OUT OF BOUNDS'
          PRINT *,'LREF, MDIM, IRANK: ',LREF,MDIM,TID
          CALL STOPIT
         END IF
        END IF                               
c
c update arrays
c
        GOTO 10
   20  CONTINUE 
       RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASFLONASE
c
c Pasvlxc is called by a slave process to deal with the calculation
c of the exchange-correlation and coulomb potential
c 
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       PARAMETER (NMAX=MPBLOCK)
       INTEGER TAG,MPTS,LPTS,NSIZE,IERR
       COMMON/FORRx/NFLO,KSPX!!,TMAT(NDH,NDH,2)
       COMMON/TMP1/POT    (MAX_PTS),RHOG(MAX_PTS,NVGRAD,MXSPN)
       DIMENSION PSIG(NMAX,10,MAX_OCC),CV(NMAX),TV(NDH       )
     &  ,PTS(NSPEED,3),GRAD(NSPEED,10,6,MAX_CON,3)
     &  ,RVECA(3,MX_GRP),ICOUNT(MAX_CON,3)
       INTEGER ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE),NFLO
c
c produce fatal error if I'm the master
c     
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASVLXC CALLED BY MASTER'
       CALL STOPIT
      END IF               
c
c get data and execute subvlxc
c
       TAG= 8701
       CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       MPTS=  ITRANS(1)
       LPTS=  ITRANS(2)
       NFLO= ITRANS(3)
       TAG= 8702
       CALL MPI_RECV(KSPX,1,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG=8703
       CALL MPI_RECV(TV(1),NDH        ,MPI_INTEGER,0,
     &                  TAG,MPI_COMM_WORLD,IERR)

        CALL FLONASE(LPTS,MPTS,CV,TV)
c
c tell mom that I'm done and report results
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
       ITRANS(1)= MPTS
       ITRANS(2)= LPTS
       ITRANS(3)=NFLO
       call flush(6)
       TAG= 8705
       CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 8706
       CALL MPI_SSEND(CV(1) ,MPTS ,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       RETURN
      END
c


CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCc
C *******************************************************************
      SUBROUTINE PAMFLO(TC)
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       PARAMETER (NDIM=MAX_PTS)
       COMMON/TMP4/FLOi(MAX_PTS)
C       COMMON/TMP41/SFLO(MPBLOCK),SMS(MPBLOCK),PT
       DIMENSION SFLO(MPBLOCK),SMS(MPBLOCK)
       INTEGER TAG,TID,IERR,IRECVSTAT(MPI_STATUS_SIZE)
       INTEGER NMAST,NSMALL,LPTS,MPTS,MODE,LREF,MDIM,NSIZE
       INTEGER IFAC,ISPN,IGRAD,IOFS,IPTS,ITRANS(3)
       DOUBLE PRECISION TC
c
c produce fatal error if Im a slave
c
       IF (IRANK.NE.0) THEN
        PRINT *,'FATAL: PAMVLXC CALLED BY SLAVE'
        CALL STOPIT
       END IF 
       TC=0.0D0
       PT=0.0D0
c
c determine maximum number of points for master, smallest allowed packet size
c     
       NMAST=  MPBLOCK/(3*NPROC+1)
       NSMALL= MPBLOCK/10 
C
C start looping over mesh points
C mode 1: all points sent out, wait for next slave to complete
C         and continue with mode 5
C      2: slaves are available for work
C      3: slaves are busy, do some work myself
C      4: slaves are busy, wait for next one to finish
C         and continue with mode 5
C      5: get data from slaves
C                        
       LPTS= 0
   10  CONTINUE
        MPTS= MIN(MPBLOCK,NMSH-LPTS)
        MODE= 0
        IF (MPTS .EQ. 0) THEN
         MODE= 1
         IF (NCALLED .EQ. 0) GOTO 20
         CALL CKCHILD(4,TID)
         MODE= 5
        ELSE
         IF (NCALLED.NE.NPROC) THEN
          MODE= 2
          NCALLED=NCALLED+1
          CALL GETTID(TID)
         ELSE
          MODE= 3
          MPTS= MIN(NMAST,MPTS)
          IF ((MPTS .LT. NSMALL) .AND. (MPTS .LT. NMSH-LPTS)) THEN
           MODE= 4
           CALL CKCHILD(4,TID)
           MODE= 5
          END IF
         END IF
        END IF
c
c mode 2,3: setup points
c
        IF ((MODE .EQ. 2) .OR. (MODE .EQ. 3)) THEN
           DO IPTS=1,MPTS
            SFLO((IPTS))=FLOi(LPTS+IPTS)
            SMS ((IPTS))=WMSH(LPTS+IPTS)
         END DO
        END IF
c
c mode 2: send job id and points, update lpts and return to beginning
c                                        
        IF (MODE .EQ. 2) THEN
         JOB= 24  
         TAG= 0
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
         NSIZE= MPTS
         ITRANS(1)= MPTS
         ITRANS(2)= LPTS
         ITRANS(3)= NSIZE
         TAG= 7701
         CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG= 7702
         CALL MPI_SSEND(SFLO(1),NSIZE,MPI_DOUBLE_PRECISION,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG=7703
         CALL MPI_SSEND(SMS (1),NSIZE,MPI_DOUBLE_PRECISION,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         LPTS= LPTS+MPTS
         GOTO 10
        END IF
c
c mode 3: call SUBVLXC
c
        LREF= LPTS
        MDIM= MPTS
        IF (MODE .EQ. 3) THEN
         JOB= 24  
         TAG= 0
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
         NSIZE= MPTS
         ITRANS(1)= MPTS
         ITRANS(2)= LPTS
         ITRANS(3)= NSIZE
         TAG= 7701
         CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG= 7702
         CALL MPI_SSEND(SFLO(1),NSIZE,MPI_DOUBLE_PRECISION,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG=7703
         CALL MPI_SSEND(SMS (1),NSIZE,MPI_DOUBLE_PRECISION,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         LPTS= LPTS+MPTS
         GOTO 10
        END IF
c
c mode 3: call SUBVLXC
c
        LREF= LPTS
        MDIM= MPTS
        IF (MODE .EQ. 3) THEN
          DO IP=1,MPTS
           TC=TC+SFLO(IP)*SFLO(IP)*SMS(IP)
          END DO
C        CALL SUBVLXC(2,LPTS,MPTS,RHOV,VXCS,VLOS,EXCVEC)
         LPTS=LPTS+MPTS
        END IF
c
c mode 5: receive data from slave
c
        IF (MODE .EQ. 5) THEN
         TAG= 7705
         CALL MPI_RECV(ITRANS(1),2,MPI_INTEGER,TID,TAG,
     &                 MPI_COMM_WORLD,IRECVSTAT,IERR)
         MDIM= ITRANS(1)
         LREF= ITRANS(2)
         TAG= 7706
         CALL MPI_RECV(PT ,1,MPI_DOUBLE_PRECISION,TID,
     &                 TAG,MPI_COMM_WORLD,IRECVSTAT,IERR)
         TC=TC+PT 
         IF ((LREF .LT. 0) .OR. (LREF+MDIM .GT. NMSH)) THEN
          PRINT *,'PAMVLXC: RETURNED INDICES ARE OUT OF BOUNDS'
          PRINT *,'LREF, MDIM, IRANK: ',LREF,MDIM,TID
          CALL STOPIT
         END IF
        END IF                               
c
c update arrays
c
        GOTO 10
   20  CONTINUE 
       RETURN
      END
c
c *******************************************************************
c
      SUBROUTINE PASFLO
c
c Pasvlxc is called by a slave process to deal with the calculation
c of the exchange-correlation and coulomb potential
c 
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       INTEGER TAG,MPTS,LPTS,NSIZE,IERR
C       COMMON/TMP41/SFLO(MPBLOCK),SMS(MPBLOCK),PT
       INTEGER ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE)
C       DOUBLE PRECISION PT,SFLO(MPBLOCK),SMS(MPBLOCK)
       DIMENSION SFLO(MPBLOCK),SMS(MPBLOCK)
c
c produce fatal error if I'm the master
c
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASVLXC CALLED BY MASTER'
       CALL STOPIT
      END IF               
c
c get data and execute subvlxc
c
       TAG= 7701
       CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       MPTS=  ITRANS(1)
       LPTS=  ITRANS(2)
       NSIZE= ITRANS(3)
       TAG= 7702
       CALL MPI_RECV(SFLO(1) ,MPTS ,MPI_DOUBLE_PRECISION,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       TAG= 7703
       CALL MPI_RECV(SMS(1)   ,MPTS ,MPI_DOUBLE_PRECISION,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
         PT=0.0D0
         DO IP=1,MPTS
           PT=PT+SFLO(IP)*SFLO(IP)*SMS(IP)
         END DO

c
c tell mom that I'm done and report results
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
       ITRANS(1)= MPTS
       ITRANS(2)= LPTS
       TAG= 7705
       CALL MPI_SSEND(ITRANS(1),2,MPI_INTEGER,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 7706
       CALL MPI_SSEND(PT ,1 ,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       RETURN
      END
c
C ********************************************************************
C
      SUBROUTINE PAMNEWWAY(MDCL,POTDV,BASPHI) 
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       PARAMETER (NMAX=MPBLOCK)
       PARAMETER (NDIM=MAX_PTS)
!       COMMON/FORRx/NFLO,KSPX!!,TMAT(NDH,NDH,2)
       INTEGER TAG,TID,IERR,IRECVSTAT(MPI_STATUS_SIZE)
       INTEGER NMAST,NSMALL,LPTS,MPTS,MODE,LREF,MDIM,NSIZE
       INTEGER IFAC,ISPN,IGRAD,IOFS,IPTS,ITRANS(3),MDCL,NFLO
       DOUBLE PRECISION TC
       DIMENSION POTDV(MAX_PTS),BASPHI(*),PV(MPBLOCK)
       DIMENSION PSIBR(MPBLOCK,5*NDH),R(3,MPBLOCK),BASPHIV(NDH*ISMAX)
       LOGICAL LSETUP
c
c produce fatal error if Im a slave
c
       IF (IRANK.NE.0) THEN
        PRINT *,'FATAL: PAMVLXC CALLED BY SLAVE'
        CALL STOPIT
       END IF 
       TV=0.0D0
       PT=0.0D0
c
c determine maximum number of points for master, smallest allowed packet size
c     
       NMAST=  MPBLOCK/(3*NPROC+1)
       NSMALL= MPBLOCK/10 
C
C start looping over mesh points
C mode 1: all points sent out, wait for next slave to complete
C         and continue with mode 5
C      2: slaves are available for work
C      3: slaves are busy, do some work myself
C      4: slaves are busy, wait for next one to finish
C         and continue with mode 5
C      5: get data from slaves
C                        
       LPTS= 0
   10  CONTINUE
        MPTS= MIN(MPBLOCK,NMSH-LPTS)
        MODE= 0
        IF (MPTS .EQ. 0) THEN
         MODE= 1
         IF (NCALLED .EQ. 0) GOTO 20
         CALL CKCHILD(4,TID)
         MODE= 5
        ELSE
         IF (NCALLED.NE.NPROC) THEN
          MODE= 2
          NCALLED=NCALLED+1
          CALL GETTID(TID)
         ELSE
          MODE= 3
          MPTS= MIN(NMAST,MPTS)
          IF ((MPTS .LT. NSMALL) .AND. (MPTS .LT. NMSH-LPTS)) THEN
           MODE= 4
           CALL CKCHILD(4,TID)
           MODE= 5
          END IF
         END IF
        END IF
c
c
c mode 2: send job id and points, update lpts and return to beginning
c                                        
        IF (MODE .EQ. 2) THEN
         JOB= 25  
         TAG= 0
         CALL MPI_SSEND(JOB,1,MPI_INTEGER,TID,TAG,MPI_COMM_WORLD,IERR)
         NSIZE= MPTS
         ITRANS(1)= MPTS
         ITRANS(2)= LPTS
         ITRANS(3)= MDCL
         TAG= 9701
         CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
         TAG=9703
         PV=0.0D0
         DO I=1,MPTS
         PV(I)=POTDV(I+LPTS)
         END DO
         CALL MPI_SSEND(PV(1),MPTS,MPI_DOUBLE_PRECISION,TID,
     &                  TAG,MPI_COMM_WORLD,IERR)
C        print*,'NFLO in MPI SEND ',NFLO,IBT,TID
         LPTS= LPTS+MPTS
         GOTO 10
        END IF
c
c mode 3: call SUBVLXC
c
        LREF= LPTS
        MDIM= MPTS
        IF (MODE .EQ. 3) THEN
          !LSETUP=.TRUE.
          BASPHIV=0.0D0
C                 call gttime(t1)
C          !CALL AGETBAS(LSETUP,0,0,QR,PSIBR,0,NBAS)
C                 call gttime(t2)
C                        print*,'TIME FOR 0 0 ',t2-t1
         PV=0.0D0
         DO I=1,MPTS
         PV(I)=POTDV(I+LPTS)
         END DO
          CALL NEWWAY(LPTS,MPTS,MDCL,PV,BASPHIV,IBT)
        print*,'NFLO in MPI_NEWWAY',NFLO,NWFS,NWF,IBT
         DO II=1,IBT
         BASPHI(II)=BASPHI(II)+BASPHIV(II)
         END DO 
         LPTS=LPTS+MPTS
        END IF
c
c mode 5: receive data from slave
c
        IF (MODE .EQ. 5) THEN
         TAG= 9705
         CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,TID,TAG,
     &                 MPI_COMM_WORLD,IRECVSTAT,IERR)
         MDIM= ITRANS(1)
         LREF= ITRANS(2)
         IBT = ITRANS(3)
       TAG= 9706
       CALL MPI_RECV(BASPHIV,IBT,MPI_DOUBLE_PRECISION,
     &                TID,TAG,MPI_COMM_WORLD,IERR)
         DO II=1,IBT
         BASPHI(II)=BASPHI(II)+BASPHIV(II)
         END DO 
         IF ((LREF .LT. 0) .OR. (LREF+MDIM .GT. NMSH)) THEN
          PRINT *,'PAMVLXC: RETURNED INDICES ARE OUT OF BOUNDS'
          PRINT *,'LREF, MDIM, IRANK: ',LREF,MDIM,TID
          CALL STOPIT
         END IF
        END IF                               
c
c update arrays
c
        GOTO 10
   20  CONTINUE 
       RETURN
      END
c
c *******************************************************************
C
      SUBROUTINE PASNEWWAY
c
c Pasvlxc is called by a slave process to deal with the calculation
c of the exchange-correlation and coulomb potential
c 
       INCLUDE 'PARAMS'
       INCLUDE 'mpif.h'
       INCLUDE 'commons.inc'
       PARAMETER (NMAX=MPBLOCK)
       INTEGER TAG,MPTS,LPTS,NSIZE,MDCL,IERR
       COMMON/FORRx/NFLO,KSPX!!,TMAT(NDH,NDH,2)
       COMMON/TMP1/POT    (MAX_PTS),RHOG(MAX_PTS,NVGRAD,MXSPN)
       DIMENSION PSIG(NMAX,10,MAX_OCC),CV(NMAX),TV(NWFS(KSPX))
     &  ,PTS(NSPEED,3),GRAD(NSPEED,10,6,MAX_CON,3)
     &  ,RVECA(3,MX_GRP),ICOUNT(MAX_CON,3)
       INTEGER ITRANS(3),IRECVSTAT(MPI_STATUS_SIZE),NFLO
       DIMENSION POTDV(MAX_PTS),BASPHIV(NDH*ISMAX),PV(MPBLOCK)
       DIMENSION PSIBR(MPBLOCK,5*NDH),R(3,MPBLOCK)
       LOGICAL LSETUP
c
c produce fatal error if I'm the master
c     
      IF (IRANK.EQ.0) THEN
       PRINT *,'FATAL: PASVLXC CALLED BY MASTER'
       CALL STOPIT
      END IF               
c
c get data and execute subvlxc
c
       TAG= 9701
       CALL MPI_RECV(ITRANS(1),3,MPI_INTEGER,0,TAG,
     &               MPI_COMM_WORLD,IRECVSTAT,IERR)
       MPTS=  ITRANS(1)
       LPTS=  ITRANS(2)
       MDCL=  ITRANS(3)
C      print*,'LPTS MPTS in slaves',LPTS, MPTS
       TAG=9703
       CALL MPI_RECV(PV(1),MPTS ,MPI_DOUBLE_PRECISION,0,
     &                  TAG,MPI_COMM_WORLD,IERR)

       BASPHIV=0.0D0
      ! LSETUP=.TRUE.
C                 call gttime(t1)
C        !CALL AGETBAS(LSETUP,0,0,QR,PSIBR,0,NBAS)
C                 call gttime(t2)
C                        print*,'TIME FOR 0 0 ',t2-t1
        CALL NEWWAY(LPTS,MPTS,MDCL,PV,BASPHIV,IBT)
CX        CALL FLONASE(LPTS,MPTS,CV,TV)
c
c tell mom that I'm done and report results
c
       TAG=1
       CALL MPI_SSEND(IRANK,1,MPI_INTEGER,0,TAG,MPI_COMM_WORLD,IERR)
       ITRANS(1)= MPTS
       ITRANS(2)= LPTS
       ITRANS(3)=IBT
       call flush(6)
       TAG= 9705
       CALL MPI_SSEND(ITRANS(1),3,MPI_INTEGER,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       TAG= 9706
       CALL MPI_SSEND(BASPHIV(1) ,IBT ,MPI_DOUBLE_PRECISION,
     &                0,TAG,MPI_COMM_WORLD,IERR)
       RETURN
      END
c

%endif
